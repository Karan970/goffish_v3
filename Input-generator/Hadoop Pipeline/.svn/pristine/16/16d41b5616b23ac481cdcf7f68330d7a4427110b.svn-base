package in.dream_lab.hadoopPipeline.cc;

import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class DriverForVornoiPartitioner {

	public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {
		
		int DEFAULT_NO_OF_REDUCERS=21;
		Configuration conf = new Configuration();
		//JOB1 Make Graph Undirected(optional) and Generate EdgeID's
//		FileSystem fs = FileSystem.get(conf);
		 //Set parameter whether to make graph undirected 
		conf.set("makeUndirected", args[1]);
		conf.set("GraphID", args[0]);
		conf.set("partition_count", args[4]);
		 // get the number of partitions 
		int numberofPartitions=Integer.parseInt(args[4]) ;
		
		String job1OutDir=args[0]+"/Job1/";
		 //String job1OutDir="SNAP_DATA/Friendster-Undirected/";
		Path OUTPUT_PATH1=new Path(job1OutDir);
		Job job1 = Job.getInstance(conf, "conf1");
	    //Set the number of reducer according to the graph size
	    job1.setNumReduceTasks(DEFAULT_NO_OF_REDUCERS);
	    job1.setJarByClass(VornoiInputReaderMapper.class);
	    job1.setMapperClass(VornoiInputReaderMapper.class);

	    job1.setReducerClass(VornoiInputReaderReducer.class);

	    job1.setOutputKeyClass(Text.class);
	    job1.setOutputValueClass(Text.class);

	    job1.setMapOutputKeyClass(Text.class);
		job1.setMapOutputValueClass(Text.class);

	    FileInputFormat.addInputPath(job1, new Path(args[2]));
	    FileOutputFormat.setOutputPath(job1, OUTPUT_PATH1);

	    job1.waitForCompletion(true);
////	    //System.exit(job1.waitForCompletion(true) ? 0 : 1);
////
////		/*JOB2 :Include vertex partition info into adjacency list*/

		String job2OutDir=args[0]+"/Job2/";
		 //String job1OutDir="SNAP_DATA/Friendster-Undirected/";
		Path OUTPUT_PATH2=new Path(job2OutDir);
		Job job2 = Job.getInstance(conf, "conf1");
	    //Set the number of reducer according to the graph size
	    job2.setNumReduceTasks(numberofPartitions);
	    job2.setJarByClass(VornoiSliceMapper.class);
	    job2.setMapperClass(VornoiSliceMapper.class);

	    job2.setReducerClass(VornoiSliceReducer.class);

	    job2.setOutputKeyClass(Text.class);
	    job2.setOutputValueClass(Text.class);

	    job2.setMapOutputKeyClass(IntWritable.class);
		job2.setMapOutputValueClass(Text.class);

	    FileInputFormat.addInputPath(job2, OUTPUT_PATH1);
	    FileOutputFormat.setOutputPath(job2, OUTPUT_PATH2);

	    
	    System.exit(job2.waitForCompletion(true) ? 0 : 1);
	    
	    

		
		
		
		
		
	}
	
}
